# Non-Maximum Suppression（NMS）概念与实现说明

本项目用于学习和验证 Non-Maximum Suppression（NMS，非极大值抑制）的基本原理及其 CUDA 实现方式。NMS 是目标检测任务中的关键后处理步骤，用于从大量重叠候选框中筛选出最具代表性的目标框。

## 1. NMS 的作用

检测模型通常会为同一个物体预测多个位置相近、重叠度高的候选框。NMS 的核心目标是在这些候选中：

- 选择得分较高且互不重叠的框；
- 抑制（移除）那些与高分框重叠度过高的冗余框；
- 使最终检测结果更加稳定、简洁且不重复。

在任何基于 bounding box 的检测模型（如 Faster R-CNN、YOLO、SSD 等）中，NMS 都是标准组件。

## 2. 基本原理

NMS 的经典流程如下：

1. **按置信度（score）降序排序候选框。**
2. 选择当前得分最高的框（称为主框）。
3. 计算主框与其余每个候选框的 IoU（Intersection over Union）。
4. 对 IoU 超过阈值的框进行抑制，即认为它们表示同一对象且质量较低。
5. 在剩余候选中重复上述步骤，直到所有框都被处理。

最终保留的框应当高质量且相互之间几乎不重叠。

## 3. IoU（Intersection over Union）计算

IoU 用于衡量两个矩形框的重叠程度，定义为：

```

IoU = 交集区域面积 / 并集区域面积

```

当 IoU 值较高时，两个框通常视为指向同一目标。在 NMS 中，通过设置阈值（如 0.5 或 0.7）来判断是否需要抑制某个框。

## 4. 本实现中的 CUDA 视角

该版本的 CUDA NMS 实现以最简形式呈现 NMS 的并行化结构，核心特征包括：

### 4.1 每个线程负责处理一个候选框

- 根据全局索引 `idx` 取得当前框数据；
- 与排序后位于前面的框逐一计算 IoU；
- 若某个之前的框已经保留，且与其 IoU 超过阈值，则当前线程将当前框标记为被抑制。

该方式等价于串行 NMS 的直接并行化，但未进行高级加速（例如 bitmask、块内共享内存等）。

### 4.2 简化的抑制逻辑

在每个线程中：

- 遍历所有编号小于自己的框；
- 只要发现一个 IoU 超阈值的情况，即可直接标记当前框为无效；
- 若遍历结束仍未被抑制，则认为该框应被保留。

该逻辑与基础 NMS 完全一致，只是采用 CUDA 并行方式执行。

### 4.3 依赖于 CPU 或上层代码的排序

NMS 的本质要求框按评分降序排列。当前实现依赖 PyTorch 的 `sort` 完成排序，再将排序后的框传入 kernel。

## 5. 实现特点与局限性

- 主要用于理解 NMS 工作原理及 CUDA 内核编写方式；
- 算法的计算复杂度较高（接近 O(N²)），对大量候选框场景效率有限；
- 未使用 bitmask、warp-level primitives、shared memory 等高级优化；
- 适合作为进一步学习高性能 NMS（如 Faster R-CNN 中的 Fast NMS、Detectron 的 Soft-NMS、批量 NMS 等）的基础。

## 6. 进一步扩展方向

该实现可作为后续优化工作的起点，例如：

- 将遍历结构转换为按块并行的 bitmask NMS；
- 使用 warp-level reduce/shuffle 降低访问延迟；
- 使用 shared memory 增强数据加载效率；
- 实现 Soft-NMS、DIoU-NMS 等变体；
- 支持批量处理（Batched NMS）。

这些方向有助于进一步提升 NMS 的速度与可扩展性。
