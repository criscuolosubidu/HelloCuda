## 1. 计算架构 & 芯片整体信息

- **GPU 架构**：NVIDIA **Ada Lovelace**
- **GPU 型号（Codename）**：**AD102**
- **制造工艺**：TSMC **4N**（NVIDIA 定制工艺）
- **晶体管数量**：约 **76.3 亿（76.3 Billion）**
- **Die 尺寸**：约 **608.5 mm²**

---

## 2. SM 数量、CUDA 核心、Tensor/RT Core 等计算单元

| 项目                    | 数值/说明                          |
|-------------------------|------------------------------------|
| GPC 数量                | 11 个                             |
| TPC 数量                | 64 个                             |
| **SM 数量**             | **128 个 SM**                     |
| **CUDA 核心总数**       | **16,384 个**                     |
| 每 SM CUDA 核心         | 128 个 FP32 CUDA Core             |
| **Tensor Core 总数**    | **512 个**（第四代）              |
| 每 SM Tensor Core       | 4 个                              |
| **RT Core 总数**        | **128 个**（第三代）              |
| 每 SM RT Core           | 1 个                              |

> 由白皮书表格可知：RTX 4090 使用的是裁剪版 AD102，启用 128 个 SM，总计 16,384 个 CUDA 核心。[1]

---

## 3. Shared Memory / L1 缓存、L2 缓存等存储层级

### 3.1 每个 SM 的 Shared Memory / L1

Ada 架构将 **L1 Data Cache 与 Shared Memory 统一设计**，在每个 SM 内按需要在 L1 Cache 与 Shared Memory 之间配置：

- **L1 Cache / Shared Memory 每 SM 容量**：**128 KB/SM**  
  （可按工作负载配置为 L1 数据缓存或 Shared Memory）[2]

### 3.2 全 GPU 范围内的缓存总量

根据官方白皮书 Appendix A 中给出的 RTX 4090 全规格表：

| 项目                           | 数值                       |
|--------------------------------|----------------------------|
| **L1 Cache / Shared Memory 总量** | **16,384 KB**（128 KB × 128 SM） |
| **L2 Cache 总量**              | **73,728 KB ≈ 72 MB**      |
| **Register File 总量**         | **32,768 KB**              |

---

## 4. 显存子系统（你关心的显存带宽）

| 项目              | 参数                               |
|-------------------|------------------------------------|
| **显存类型**      | **GDDR6X**                         |
| **显存容量**      | **24 GB**                          |
| **显存位宽**      | **384-bit**                        |
| **显存速率**      | **21 Gbps（有效数据率）**          |
| **显存带宽**      | **1,008 GB/s**（约 1.0 TB/s）      |

计算关系为：  
带宽 ≈ 21 Gbps × 384 bit ÷ 8 / 10⁹ ≈ 1008 GB/s，与官方规格一致。[1]

---

## 5. 频率与理论算力

| 项目                    | 数值/说明                |
|-------------------------|--------------------------|
| 基础频率（Base Clock）  | 约 **2,235 MHz**         |
| 加速频率（Boost Clock） | **2,520 MHz**            |
| **FP32 峰值算力**       | **82.6 TFLOPS**（不含 Tensor）[1] |

> FP32 峰值由 CUDA 核心数量 × 频率 × 每周期运算次数推算，白皮书中直接给出约 82.6 TFLOPS。[1]

---

## 6. 功耗、接口及视频编解码单元

| 项目                         | 数值/说明                             |
|------------------------------|---------------------------------------|
| **TGP（Total Graphics Power）** | **450 W**                           |
| PCIe 接口                    | PCI Express **Gen 4 x16**            |
| 供电接口（公版）             | 16-pin（PCIe 5.0 12VHPWR 转 3×8-pin）|
| NVENC                        | 2 个（第 8 代 NVENC）                 |
| NVDEC                        | 1 个（第 5 代 NVDEC）                 |

---

## 7. 总结（针对你提问中的关键点）

按照你原问题中的关注项，核心要点可以浓缩为：

1. **计算架构**：
    - **NVIDIA Ada Lovelace** 架构，芯片代号 **AD102**。

2. **SM 数量**：
    - RTX 4090 启用 **128 个 SM**。

3. **Shared Memory 大小**：
    - 每个 SM 内部的统一 L1/Shared Memory 容量为 **128 KB/SM**；
    - 全卡合计 **16,384 KB** L1/Shared Memory。

4. **显存带宽**：
    - 24 GB GDDR6X，384-bit，总带宽 **1,008 GB/s（约 1 TB/s）**。

5. **其他关键 GPU 信息**：
    - CUDA 核心：16,384 个
    - Tensor Cores：512 个（第四代）
    - RT Cores：128 个（第三代）
    - L2 Cache：约 **72 MB**（73,728 KB）
    - 制程工艺：TSMC 4N
    - FP32 理论算力：约 82.6 TFLOPS
    - 功耗 TGP：450 W

如果你后续是做 **CUDA 编程/深度学习调优**，最需要记住的是：
- 每 SM 可用的 **Shared Memory 上限为 128 KB**（实际可分配容量需按 CUDA 运行时时的配置和保留空间略小），
- 全卡 24 GB 显存、1 TB/s 级别带宽、72 MB L2 Cache，在大模型推理/训练和高分辨率渲染中对吞吐和延迟有明显优势。

---

**References**

[1] Appendix A – GeForce RTX 4090 GPU Full Specifications. NVIDIA Ada GPU Architecture Whitepaper. <https://images.nvidia.com/aem-dam/Solutions/geforce/ada/nvidia-ada-gpu-architecture.pdf>  
[2] L1 cache / Shared memory per SM (Ada SM description). NVIDIA Ada GPU Architecture Whitepaper. <https://images.nvidia.com/aem-dam/Solutions/geforce/ada/nvidia-ada-gpu-architecture.pdf>